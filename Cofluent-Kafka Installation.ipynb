{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxeKI2vJAJCFsvVb1sk4YU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Britapollo/Nairobi-Metropolitan-Real-Time-Traffic-Update-project/blob/main/Cofluent-Kafka%20Installation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7RcPw_HLwPM",
        "outputId": "03857ddb-3f32-497c-b9a1-539321a1ff17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting confluent-kafka\n",
            "  Downloading confluent_kafka-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: confluent-kafka\n",
            "Successfully installed confluent-kafka-2.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install confluent-kafka"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "import socket\n",
        "\n",
        "conf = {'bootstrap.servers': 'host1:9092,host2:9092',\n",
        "        'client.id': socket.gethostname()}\n",
        "\n",
        "producer = Producer(conf)"
      ],
      "metadata": {
        "id": "o1_DNvokMUUk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "import socket\n",
        "\n",
        "conf = {'bootstrap.servers': 'pkc-abcd85.us-west-2.aws.confluent.cloud:9092',\n",
        "        'security.protocol': 'SASL_SSL',\n",
        "        'sasl.mechanism': 'PLAIN',\n",
        "        'sasl.username': '<J6G6NJB6ACKYDKLC>',\n",
        "        'sasl.password': '<QfeQLTh4ZKYO9sSAft9heBCC6sJWNKr+2Ukz4KoOeY5csPRyVLMbJlgwr8LnXZFl>',\n",
        "        'client.id': socket.gethostname()}\n",
        "\n",
        "producer = Producer(conf)"
      ],
      "metadata": {
        "id": "GmbVibGaMhPy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "producer.produce(topic, key=\"key\", value=\"value\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "JtzOebiEMnLI",
        "outputId": "2f8bf614-3ad2-4244-c7d4-5868c01353d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'topic' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-300b72f3bcb7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'topic' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "topic = \"Traffic_Updates\"\n",
        "producer = Producer({\"bootstrap.servers\": \"localhost:9092\"})\n",
        "producer.produce(topic, key=\"key\", value=\"value\")\n",
        "producer.flush()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbcTeoRHNbkn",
        "outputId": "e5aa48fe-9d06-40d5-9d48-0000598dfc25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def acked(err, msg):\n",
        "    if err is not None:\n",
        "        print(\"Failed to deliver message: %s: %s\" % (str(msg), str(err)))\n",
        "    else:\n",
        "        print(\"Message produced: %s\" % (str(msg)))\n",
        "\n",
        "producer.produce(topic, key=\"key\", value=\"value\", callback=acked)\n",
        "\n",
        "# Wait up to 1 second for events. Callbacks will be invoked during\n",
        "# this method call if the message is acknowledged.\n",
        "producer.poll(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvvHo4pOPSRm",
        "outputId": "3b3fd582-2b18-434c-8f32-66962e8822da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer\n",
        "\n",
        "conf = {'bootstrap.servers': 'host1:9092,host2:9092',\n",
        "        'group.id': 'foo',\n",
        "        'auto.offset.reset': 'smallest'}\n",
        "\n",
        "consumer = Consumer(conf)"
      ],
      "metadata": {
        "id": "WD1IeXboR4qY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer\n",
        "\n",
        "conf = {'bootstrap.servers': 'pkc-abcd85.us-west-2.aws.confluent.cloud:9092',\n",
        "        'security.protocol': 'SASL_SSL',\n",
        "        'sasl.mechanism': 'PLAIN',\n",
        "        'sasl.username': '<J6G6NJB6ACKYDKLC>',\n",
        "        'sasl.password': '<QfeQLTh4ZKYO9sSAft9heBCC6sJWNKr+2Ukz4KoOeY5csPRyVLMbJlgwr8LnXZFl>',\n",
        "        'group.id': 'foo',\n",
        "        'auto.offset.reset': 'smallest'}\n",
        "\n",
        "consumer = Consumer(conf)"
      ],
      "metadata": {
        "id": "a5xVao9ZS5z5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer\n",
        "\n",
        "conf = {'bootstrap.servers': 'host1:9092,host2:9092',\n",
        "        'group.id': 'foo',\n",
        "        'enable.auto.commit': 'false',\n",
        "        'auto.offset.reset': 'earliest'}\n",
        "\n",
        "consumer = Consumer(conf)\n"
      ],
      "metadata": {
        "id": "Ytt5Ne4sTlbJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running = True\n",
        "\n",
        "def basic_consume_loop(consumer, topics):\n",
        "    try:\n",
        "        consumer.subscribe(topics)\n",
        "\n",
        "        while running:\n",
        "            msg = consumer.poll(timeout=1.0)\n",
        "            if msg is None: continue\n",
        "\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
        "                    # End of partition event\n",
        "                    sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n",
        "                                     (msg.topic(), msg.partition(), msg.offset()))\n",
        "                elif msg.error():\n",
        "                    raise KafkaException(msg.error())\n",
        "            else:\n",
        "                msg_process(msg)\n",
        "    finally:\n",
        "        # Close down consumer to commit final offsets.\n",
        "        consumer.close()\n",
        "\n",
        "def shutdown():\n",
        "    running = False"
      ],
      "metadata": {
        "id": "3VcADYfKT9XA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def consume_loop(consumer, topics):\n",
        "    try:\n",
        "        consumer.subscribe(topics)\n",
        "\n",
        "        msg_count = 0\n",
        "        while running:\n",
        "            msg = consumer.poll(timeout=1.0)\n",
        "            if msg is None: continue\n",
        "\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
        "                    # End of partition event\n",
        "                    sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n",
        "                                     (msg.topic(), msg.partition(), msg.offset()))\n",
        "                elif msg.error():\n",
        "                    raise KafkaException(msg.error())\n",
        "            else:\n",
        "                msg_process(msg)\n",
        "                msg_count += 1\n",
        "                if msg_count % MIN_COMMIT_COUNT == 0:\n",
        "                    consumer.commit(asynchronous=False)\n",
        "    finally:\n",
        "        # Close down consumer to commit final offsets.\n",
        "        consumer.close()"
      ],
      "metadata": {
        "id": "FwJsTWuKUXnF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def consume_loop(consumer, topics):\n",
        "    try:\n",
        "        consumer.subscribe(topics)\n",
        "\n",
        "        while running:\n",
        "            msg = consumer.poll(timeout=1.0)\n",
        "            if msg is None: continue\n",
        "\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
        "                    # End of partition event\n",
        "                    sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n",
        "                                     (msg.topic(), msg.partition(), msg.offset()))\n",
        "                elif msg.error():\n",
        "                    raise KafkaException(msg.error())\n",
        "            else:\n",
        "                consumer.commit(asynchronous=False)\n",
        "                msg_process(msg)\n",
        "\n",
        "    finally:\n",
        "        # Close down consumer to commit final offsets.\n",
        "        consumer.close()"
      ],
      "metadata": {
        "id": "2YRhdU91U0vm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer\n",
        "\n",
        "def commit_completed(err, partitions):\n",
        "    if err:\n",
        "        print(str(err))\n",
        "    else:\n",
        "        print(\"Committed partition offsets: \" + str(partitions))\n",
        "\n",
        "conf = {'bootstrap.servers': \"host1:9092,host2:9092\",\n",
        "        'group.id': \"foo\",\n",
        "        'default.topic.config': {'auto.offset.reset': 'smallest'},\n",
        "        'on_commit': commit_completed}\n",
        "\n",
        "consumer = Consumer(conf)"
      ],
      "metadata": {
        "id": "Y8c9HjOYVIWh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvnmVAn2WV2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}